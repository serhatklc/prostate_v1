{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  GCFS + Nested CV + Hybrid RFâ€“LightGBM Model for Prostate Cancer Biomarkers\n",
    "\n",
    "This notebook reproduces the machine learning workflow from the manuscript:\n",
    "\n",
    "> *Bioinformatics and Machine Learning Integration Reveals a Novel 4-Gene Biomarker Model for Prostate Cancer.*\n",
    "\n",
    "**Pipeline overview:**\n",
    "- GCFS (Graph-Convolutional Feature Selection)\n",
    "- Nested cross-validation (10Ã—5)\n",
    "- Hybrid RF + LightGBM model with Logistic Regression meta-learner\n",
    "- 70/30 hold-out internal test\n",
    "- External validation (e.g., GSE46602 dataset)\n",
    "- ROC analysis, bootstrap 95% CI (n=1000), and DeLong test\n",
    "\n",
    "### Expected input files\n",
    "- `DEG_expression_matrix.csv` : discovery expression matrix, shape **(samples Ã— genes)**\n",
    "- `labels.csv` : discovery labels with a column named **`class`** (0/1 or Normal/Tumor)\n",
    "- `validation_expression_matrix.csv` : external validation matrix, same genes if possible\n",
    "- `validation_labels.csv` : validation labels with a column named **`class`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, roc_curve, auc\n",
    "import scipy.stats as st\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "plt.rcParams['figure.dpi'] = 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GCFS Feature Selector ===\n",
    "class GCFS(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Simplified Graph-Convolutional Feature Selection (GCFS)\n",
    "    Each gene score = variance(gene) + mean(neighborhood expression)\n",
    "    \"\"\"\n",
    "    def __init__(self, edges, top_k=15):\n",
    "        self.edges = edges\n",
    "        self.top_k = top_k\n",
    "        self.graph = nx.Graph()\n",
    "        self.graph.add_edges_from(edges)\n",
    "        self.selected_features_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        scores = {}\n",
    "        for gene in X.columns:\n",
    "            neighbors = list(self.graph.neighbors(gene)) if gene in self.graph else []\n",
    "            neighbor_mean = X[neighbors].mean(axis=1).mean() if neighbors else 0.0\n",
    "            scores[gene] = float(np.var(X[gene].values)) + float(neighbor_mean)\n",
    "        self.selected_features_ = sorted(scores, key=scores.get, reverse=True)[: self.top_k]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.selected_features_ is None:\n",
    "            raise RuntimeError(\"GCFS must be fit before transform.\")\n",
    "        keep = [g for g in self.selected_features_ if g in X.columns]\n",
    "        return X[keep].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helper functions ===\n",
    "def compute_metrics(y_true, y_prob, threshold=0.5):\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    return {\n",
    "        'AUC': roc_auc_score(y_true, y_prob),\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Sensitivity': recall_score(y_true, y_pred, pos_label=1),\n",
    "        'Specificity': recall_score(y_true, y_pred, pos_label=0)\n",
    "    }\n",
    "\n",
    "def ParameterGridCompat(param_grid):\n",
    "    if not param_grid:\n",
    "        yield {}\n",
    "        return\n",
    "    keys = list(param_grid.keys())\n",
    "    vals = [v if isinstance(v, list) else [v] for v in param_grid.values()]\n",
    "    for combo in product(*vals):\n",
    "        yield dict(zip(keys, combo))\n",
    "\n",
    "def bootstrap_auc_ci(y_true, y_prob, n_boot=1000, random_state=42, alpha=0.05):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    aucs = []\n",
    "    n = len(y_true)\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(y_true[idx], y_prob[idx]))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    aucs = np.array(aucs)\n",
    "    return np.mean(aucs), (np.percentile(aucs, 2.5), np.percentile(aucs, 97.5))\n",
    "\n",
    "def delong_roc_test(y_true, y_pred1, y_pred2):\n",
    "    def compute_midrank(x):\n",
    "        J = np.argsort(x)\n",
    "        Z = x[J]\n",
    "        N = len(x)\n",
    "        T = np.zeros(N, dtype=float)\n",
    "        i = 0\n",
    "        while i < N:\n",
    "            j = i\n",
    "            while j < N and Z[j] == Z[i]:\n",
    "                j += 1\n",
    "            T[i:j] = 0.5 * (i + j - 1)\n",
    "            i = j\n",
    "        T2 = np.empty(N, dtype=float)\n",
    "        T2[J] = T + 1\n",
    "        return T2\n",
    "\n",
    "    def calc_auc_cov(y_true, y_pred):\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        pos = y_pred[y_true == 1]\n",
    "        neg = y_pred[y_true == 0]\n",
    "        n1, n2 = len(pos), len(neg)\n",
    "        all_ranks = compute_midrank(np.concatenate([pos, neg]))\n",
    "        V10 = all_ranks[:n1] - (n1 + 1) / 2\n",
    "        V01 = all_ranks[n1:] - (n1 + 1) / 2\n",
    "        auc_val = (V10.mean() - V01.mean()) / (n1 * n2)\n",
    "        s10 = np.cov(V10)\n",
    "        s01 = np.cov(V01)\n",
    "        s = s10 / n1 + s01 / n2\n",
    "        return auc_val, s\n",
    "\n",
    "    auc1, s1 = calc_auc_cov(y_true, y_pred1)\n",
    "    auc2, s2 = calc_auc_cov(y_true, y_pred2)\n",
    "    se = np.sqrt(s1 + s2)\n",
    "    z = (auc1 - auc2) / se\n",
    "    p_val = 2 * (1 - st.norm.cdf(abs(z)))\n",
    "    return auc1, auc2, z, p_val\n",
    "\n",
    "def plot_roc_curves(y_true, preds_dict, title=\"ROC Curves\"):\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    for name, y_prob in preds_dict.items():\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f\"{name} (AUC = {roc_auc:.3f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    plt.xlabel('1 - Specificity (FPR)')\n",
    "    plt.ylabel('Sensitivity (TPR)')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Nested Hybrid Trainer (RF + LGBM + Meta LR) ===\n",
    "@dataclass\n",
    "class NestedHybridTrainer:\n",
    "    ppi_edges: list\n",
    "    top_k: int = 15\n",
    "    outer_splits: int = 10\n",
    "    inner_splits: int = 5\n",
    "    random_state: int = RANDOM_STATE\n",
    "    best_params_: dict = field(default_factory=dict)\n",
    "\n",
    "    def _inner_search(self, base_estimator, X, y, param_grid):\n",
    "        if not param_grid:\n",
    "            return {}\n",
    "        skf = StratifiedKFold(n_splits=self.inner_splits, shuffle=True, random_state=self.random_state)\n",
    "        best_auc, best_params = -np.inf, {}\n",
    "        for combo in ParameterGridCompat(param_grid):\n",
    "            aucs = []\n",
    "            for tr, va in skf.split(X, y):\n",
    "                X_tr, X_va = X.iloc[tr], X.iloc[va]\n",
    "                y_tr, y_va = y.iloc[tr], y.iloc[va]\n",
    "                pipe = Pipeline([\n",
    "                    (\"gcfs\", GCFS(self.ppi_edges, self.top_k)),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"clf\", clone(base_estimator).set_params(**combo))\n",
    "                ])\n",
    "                pipe.fit(X_tr, y_tr)\n",
    "                prob = pipe.predict_proba(X_va)[:, 1]\n",
    "                aucs.append(roc_auc_score(y_va, prob))\n",
    "            mean_auc = np.mean(aucs)\n",
    "            if mean_auc > best_auc:\n",
    "                best_auc, best_params = mean_auc, combo\n",
    "        return best_params\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        # Base models (limited grids as per manuscript spirit)\n",
    "        models = {\n",
    "            \"rf\": RandomForestClassifier(random_state=self.random_state),\n",
    "            \"lgb\": LGBMClassifier(random_state=self.random_state)\n",
    "        }\n",
    "        grids = {\n",
    "            \"rf\":  {\"n_estimators\": [300, 500], \"max_features\": [\"sqrt\", None]},\n",
    "            \"lgb\": {\"num_leaves\": [31, 63], \"n_estimators\": [100, 200]}\n",
    "        }\n",
    "\n",
    "        # Inner search (hyperparameter selection)\n",
    "        for name, est in models.items():\n",
    "            self.best_params_[name] = self._inner_search(est, X_train, y_train, grids[name])\n",
    "\n",
    "        # Outer CV to generate OOF predictions for stacking\n",
    "        outer = StratifiedKFold(n_splits=self.outer_splits, shuffle=True, random_state=self.random_state)\n",
    "        oof_rf = np.zeros(len(y_train))\n",
    "        oof_lgb = np.zeros(len(y_train))\n",
    "\n",
    "        for tr_idx, va_idx in outer.split(X_train, y_train):\n",
    "            X_tr, X_va = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "            y_tr, y_va = y_train.iloc[tr_idx], y_train.iloc[va_idx]\n",
    "\n",
    "            rf_pipe = Pipeline([\n",
    "                (\"gcfs\", GCFS(self.ppi_edges, self.top_k)),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"clf\", RandomForestClassifier(random_state=self.random_state, **self.best_params_[\"rf\"]))\n",
    "            ])\n",
    "            lgb_pipe = Pipeline([\n",
    "                (\"gcfs\", GCFS(self.ppi_edges, self.top_k)),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"clf\", LGBMClassifier(random_state=self.random_state, **self.best_params_[\"lgb\"]))\n",
    "            ])\n",
    "            rf_pipe.fit(X_tr, y_tr)\n",
    "            lgb_pipe.fit(X_tr, y_tr)\n",
    "            oof_rf[va_idx] = rf_pipe.predict_proba(X_va)[:, 1]\n",
    "            oof_lgb[va_idx] = lgb_pipe.predict_proba(X_va)[:, 1]\n",
    "\n",
    "        # Meta-learner on OOF\n",
    "        meta_X = np.vstack([oof_rf, oof_lgb]).T\n",
    "        self.meta_ = LogisticRegression(random_state=self.random_state)\n",
    "        self.meta_.fit(meta_X, y_train)\n",
    "\n",
    "        # Final base models on full train\n",
    "        self.rf_final_ = rf_pipe.fit(X_train, y_train)\n",
    "        self.lgb_final_ = lgb_pipe.fit(X_train, y_train)\n",
    "\n",
    "    def evaluate(self, X, y, title=\"Evaluation\"):\n",
    "        rf_pred = self.rf_final_.predict_proba(X)[:, 1]\n",
    "        lgb_pred = self.lgb_final_.predict_proba(X)[:, 1]\n",
    "        hybrid_pred = self.meta_.predict_proba(np.vstack([rf_pred, lgb_pred]).T)[:, 1]\n",
    "\n",
    "        metrics = compute_metrics(y, hybrid_pred)\n",
    "        mean_auc, (ci_low, ci_high) = bootstrap_auc_ci(y.values, hybrid_pred)\n",
    "        auc1, auc2, z, p = delong_roc_test(y.values, hybrid_pred, lgb_pred)\n",
    "\n",
    "        print(f\"\\n=== {title} ===\")\n",
    "        for k, v in metrics.items():\n",
    "            print(f\"{k}: {v:.4f}\")\n",
    "        print(f\"Bootstrap AUC 95% CI: [{ci_low:.3f}, {ci_high:.3f}]\")\n",
    "        print(f\"DeLong vs LGBM: z={z:.3f}, p={p:.4f}\")\n",
    "\n",
    "        plot_roc_curves(y, {\"Hybrid\": hybrid_pred, \"RF\": rf_pred, \"LGBM\": lgb_pred}, title=title)\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load data (edit paths if needed) ===\n",
    "X = pd.read_csv(\"DEG_expression_matrix.csv\", index_col=0)\n",
    "y = pd.read_csv(\"labels.csv\")[\"class\"]\n",
    "if y.dtype == object:\n",
    "    y = y.astype(\"category\").cat.codes\n",
    "\n",
    "# External validation\n",
    "X_val = pd.read_csv(\"validation_expression_matrix.csv\", index_col=0)\n",
    "y_val = pd.read_csv(\"validation_labels.csv\")[\"class\"]\n",
    "if y_val.dtype == object:\n",
    "    y_val = y_val.astype(\"category\").cat.codes\n",
    "\n",
    "# Align columns (genes) between train/test/val if necessary\n",
    "common_cols = X.columns.intersection(X_val.columns)\n",
    "X = X[common_cols]\n",
    "X_val = X_val[common_cols]\n",
    "\n",
    "# 70/30 split for internal test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Example STRING-based PPI edges (extend with your network)\n",
    "ppi_edges = [\n",
    "    (\"GFUS\", \"ARHGAP8\"),\n",
    "    (\"ARHGAP8\", \"NBL1\"),\n",
    "    (\"NBL1\", \"ACTB\"),\n",
    "    (\"GFUS\", \"ACTB\")\n",
    "]\n",
    "\n",
    "trainer = NestedHybridTrainer(ppi_edges=ppi_edges, top_k=15)\n",
    "trainer.fit(X_train, y_train)\n",
    "\n",
    "# Internal test evaluation\n",
    "trainer.evaluate(X_test, y_test, title=\"Internal Test (Hold-out 30%)\")\n",
    "\n",
    "# External validation evaluation\n",
    "trainer.evaluate(X_val, y_val, title=\"External Validation (Independent Dataset)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}